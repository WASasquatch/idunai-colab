{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WASasquatch/idunai-colab/blob/main/Idun_AI_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y6RXjS1tTji"
      },
      "source": [
        "# Idun.AI Colab Generator v0.1 ![visitors](https://visitor-badge.glitch.me/badge?page_id=IdunAIColab&left_color=blue&right_color=orange) [![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](#)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Terms of Use"
      ],
      "metadata": {
        "id": "b9SlHT7rJ4Lt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stablity.AI Model Terms of Use\n",
        "\n",
        "**By using this Notebook, you agree to the following Terms of Use, and license**\n",
        "\n",
        "This model is open access and available to all, with a CreativeML OpenRAIL-M license further specifying rights and usage.\n",
        "\n",
        "The CreativeML OpenRAIL License specifies:\n",
        "1. You can't use the model to deliberately produce nor share illegal or harmful outputs or content\n",
        "2. CompVis claims no rights on the outputs you generate, you are free to use them and are accountable for their use which must not go against the provisions set in the license\n",
        "3. You may re-distribute the weights and use the model commercially and/or as a service. If you do, please be aware you have to include the same use restrictions as the ones in the license and share a copy of the CreativeML OpenRAIL-M to all your users (please read the license entirely and carefully)\n",
        "\n",
        "Please read the full license here: https://huggingface.co/spaces/CompVis/stable-diffusion-license "
      ],
      "metadata": {
        "id": "CmeRfQ7LJ1PT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Idun**.<font color=\"default\">AI</font> Generator"
      ],
      "metadata": {
        "id": "ha0jrOk_Vx80"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ucr5_i21xSjv",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title <font size=\"5\" color=\"default\">Settings & Create</font>\n",
        "\n",
        "# Import future print\n",
        "from __future__ import print_function\n",
        "try:\n",
        "    import __builtin__\n",
        "except ImportError:\n",
        "    import builtins as __builtin__\n",
        "\n",
        "# Emoticon fun!\n",
        "import subprocess\n",
        "try:\n",
        "    import emoji\n",
        "except ImportError:\n",
        "     multipip_res = subprocess.run(['pip', '-q', 'install', 'emoji'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "finally:\n",
        "    import emoji\n",
        "\n",
        "print(subprocess.run('python -m ensurepip --upgrade'.split(' '), stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "\n",
        "# Override Print Function\n",
        "def print(message, *args, **kwargs):\n",
        "    if 'defaultprint' in kwargs:\n",
        "        kwargs.pop('defaultprint')\n",
        "        return __builtin__.print(message, *args, **kwargs)\n",
        "    else:\n",
        "        return __builtin__.print(emoji.emojize(message), *args, **kwargs)\n",
        "\n",
        "import subprocess\n",
        "try:\n",
        "    print(subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "    nvidiasmi_simple = subprocess.run(['nvidia-smi', '-L'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    gpu_name = nvidiasmi_simple.split(':')[1].split('(')[0].strip()\n",
        "except Exception as e:\n",
        "    raise e\n",
        "\n",
        "USE_DRIVE_FOR_MODELS = False\n",
        "USE_DRIVE_FOR_LOCAL_COPIES = False\n",
        "CLEAR_SETUP_LOG = True \n",
        "SUPPRESS_WARNINGS = True\n",
        "\n",
        "import os, sys, time, torch, gc, requests, io, shutil, json\n",
        "\n",
        "settings_template = {\n",
        "    'setup': {\n",
        "        'CLEAR_SETUP_LOG': False,\n",
        "        'SUPPRESS_WARNINGS': True,\n",
        "    },\n",
        "    'prompts': {\n",
        "        'PROMPT': None,\n",
        "        'PROMPT_FILE': None,\n",
        "        'PROMPT_STYLE': None,\n",
        "        'NEW_NSP_ON_ITERATION': True,\n",
        "    },\n",
        "    'inits': {\n",
        "        'INIT_IMAGE': None,\n",
        "        'INIT_MASK': None,\n",
        "        'INIT_SCALE': None,\n",
        "        'RECURSIVE_EVOLUTION': False,\n",
        "    },\n",
        "    'diffusion_settings': {\n",
        "        'MODEL_ID': None,\n",
        "        'SAMPLER': None,\n",
        "        'DDIM_ETA': None,\n",
        "        'STEPS': None,\n",
        "        'SEED': None,\n",
        "        'MAX_SEED': None,\n",
        "        'INCREMENT_ITERATION_SEED': None,\n",
        "        'NUM_ITERS': None,\n",
        "        'WIDTH': None,\n",
        "        'HEIGHT': None,\n",
        "        'SCALE': None,\n",
        "        'PRECISION': None,\n",
        "        'IMAGES_FOLDER': None,\n",
        "        'CACHE_PIPELINES': False,\n",
        "        'RECACHE_PIPES': False,\n",
        "        'SKIP_DIFFUSION_RUN': False,\n",
        "        'ENABLE_NSFW_FILTER': False,\n",
        "        'ENABLE_ATTENTION_SLICES': True,\n",
        "        'LOW_VRAM_PATCH': True,\n",
        "    },\n",
        "    'upscalers': {\n",
        "        'IMAGE_UPSCALER': None,\n",
        "        'UPSCALE_AMOUNT': None,\n",
        "        'ESRGAN_MODE': None,\n",
        "        'CODEFORMER_UPSCALE_AMOUNT': None,\n",
        "        'CODEFORMER_FIDELITY': None,\n",
        "    },\n",
        "    'image_processing': {\n",
        "        'KEEP_ONLY_FINAL_IMAGE': False,\n",
        "        'SCALE_DOWN_ENHANCEMENTS_FOR_ESRGAN': True,\n",
        "        'SHARPEN_AMOUNT': None,\n",
        "    },\n",
        "    'other_settings': {\n",
        "        'IMAGES_DISPLAY_ABOVE_LOG': False,\n",
        "        'USE_BASIC_IMAGE_DISPLAY': True,\n",
        "        'CLEAR_LOG_BETWEEN_ITERATIONS': True,\n",
        "    },\n",
        "}\n",
        "\n",
        "# Enable third-party widgets\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "# SETUP BASE DIRECTORIES\n",
        "OUTDIR = '/content/Stable_Diffusion/images_out'\n",
        "\n",
        "STABLE_DIFFUSION_WORKDIR = '/content/Stable_Diffusion'\n",
        "GDRIVE_WORKDIR = '/content/drive/MyDrive/AI/Stable_Diffusion'\n",
        "\n",
        "if not os.path.exists(STABLE_DIFFUSION_WORKDIR):\n",
        "    os.makedirs(STABLE_DIFFUSION_WORKDIR)\n",
        "\n",
        "os.chdir(STABLE_DIFFUSION_WORKDIR)\n",
        "sys.path.append(STABLE_DIFFUSION_WORKDIR)\n",
        "\n",
        "drive_model_cache = f'{GDRIVE_WORKDIR}/model_cache'\n",
        "model_cache = f'{STABLE_DIFFUSION_WORKDIR}/model_cache'\n",
        "pipe_cache = f'{STABLE_DIFFUSION_WORKDIR}/cache'\n",
        "\n",
        "moved_from_cache = False\n",
        "last_model = None\n",
        "\n",
        "if not os.path.exists(model_cache):\n",
        "    os.makedirs(model_cache)\n",
        "\n",
        "if not os.path.exists(pipe_cache):\n",
        "    os.makedirs(pipe_cache)\n",
        "\n",
        "# DEFINE NECESSARY FUNCTIONS\n",
        "\n",
        "def packages():\n",
        "    import sys, subprocess\n",
        "    return [r.decode().split('==')[0] for r in subprocess.check_output([sys.executable, '-m', 'pip', 'freeze']).split()]\n",
        "\n",
        "def wget(url, outputdir):\n",
        "    res = None\n",
        "    try:\n",
        "        res = subprocess.run(['wget', '-q', '--show-progress', url, '-P', f'{outputdir}'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    except OSError as e:\n",
        "        raise e\n",
        "    finally:\n",
        "        if res and res.strip() is not '':\n",
        "            print(res)\n",
        "\n",
        "def wgeto(url, outputdir):\n",
        "    res = None\n",
        "    try:\n",
        "        res = subprocess.run(['wget', '-q', '--show-progress', url, '-O', f'{outputdir}'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    except OSError as e:\n",
        "        raise e\n",
        "    finally:\n",
        "        if res and res.strip() is not '':\n",
        "            print(res)\n",
        "\n",
        "def plotSettings(settingsType=None, locals=None):\n",
        "    global settings\n",
        "    if settingsType and settings.__contains__(settingsType) and type(locals) is dict:\n",
        "        for k in settings[settingsType].keys():\n",
        "            if locals.keys().__contains__(k):\n",
        "                settings[settingsType][k] = locals[k]\n",
        "\n",
        "def fetch_bytes(url_or_path):\n",
        "    if str(url_or_path).startswith('http://') or str(url_or_path).startswith('https://'):\n",
        "        from urllib.request import urlopen \n",
        "        return urlopen(url_or_path) \n",
        "    return open(url_or_path, 'r')\n",
        "\n",
        "def fetch(url_or_path):\n",
        "    if str(url_or_path).startswith('http://') or str(url_or_path).startswith('https://'):\n",
        "        r = requests.get(url_or_path)\n",
        "        r.raise_for_status()\n",
        "        fd = io.BytesIO()\n",
        "        fd.write(r.content)\n",
        "        fd.seek(0)\n",
        "        return fd\n",
        "    return open(url_or_path, 'rb')\n",
        "\n",
        "def clear():\n",
        "    from IPython.display import clear_output; return clear_output()\n",
        "\n",
        "def time_format(seconds: int):\n",
        "    if seconds is not None:\n",
        "        seconds = int(seconds)\n",
        "        d = seconds // (3600 * 24)\n",
        "        h = seconds // 3600 % 24\n",
        "        m = seconds % 3600 // 60\n",
        "        s = seconds % 3600 % 60\n",
        "        ms = round(seconds * 1000)\n",
        "        if d > 0:\n",
        "            return '{:02d}D {:02d}H {:02d}m {:02d}s'.format(d, h, m, s)\n",
        "        elif h > 0:\n",
        "            return '{:02d}H {:02d}m {:02d}s'.format(h, m, s)\n",
        "        elif m > 0:\n",
        "            return '{:02d}m {:02d}s'.format(m, s)\n",
        "        elif s > 0:\n",
        "            return '{:02d}s'.format(s)\n",
        "        elif ms > 0:\n",
        "            return '{:02d}ms'.format(ms)\n",
        "    return '0s'\n",
        "\n",
        "def text2seed(string, max):\n",
        "    seed = None\n",
        "    def digits(n, max):\n",
        "        import math\n",
        "        ndigits = int(math.log10(n))+1\n",
        "        try:\n",
        "            return n//int(10**(ndigits-max))\n",
        "        except ZeroDivisionError:\n",
        "            return n\n",
        "    if string:\n",
        "        for chr in [*string]:\n",
        "            if seed is None:\n",
        "                seed = str(ord(chr))\n",
        "            else:\n",
        "                seed += str(ord(chr))\n",
        "        seed = digits(int(seed), max)\n",
        "    return seed\n",
        "\n",
        "def gpu_memory_usage(gpu_id):\n",
        "    command = f\"nvidia-smi --id={gpu_id} --query-gpu=memory.used --format=csv\"\n",
        "    output_cmd = subprocess.check_output(command.split())\n",
        "    memory_used = output_cmd.decode(\"ascii\").split(\"\\n\")[1]\n",
        "    memory_used = int(memory_used.split()[0])\n",
        "    return memory_used\n",
        "\n",
        "def gpu_memory_total(gpu_id):\n",
        "    command = f\"nvidia-smi --id={gpu_id} --query-gpu=memory.total --format=csv\"\n",
        "    output_cmd = subprocess.check_output(command.split())\n",
        "    memory_used = output_cmd.decode(\"ascii\").split(\"\\n\")[1]\n",
        "    memory_used = int(memory_used.split()[0])\n",
        "    return memory_used\n",
        "\n",
        "def clean_env(v=False, device=0):\n",
        "    import time\n",
        "    cuda_availabe = torch.cuda.is_available()\n",
        "    mem_used = gpu_memory_usage(device)\n",
        "    mem_total = gpu_memory_total(device)\n",
        "    if v: print(f'VRAM Total: {mem_total}mb, VRAM Allocatd: {mem_used}mb')\n",
        "    stt = int(time.time())\n",
        "    if cuda_availabe:\n",
        "        a = None\n",
        "        try:\n",
        "            a = torch.zeros(sys.maxsize, dtype=torch.int8).cuda()\n",
        "        except Exception:\n",
        "            pass\n",
        "        finally:\n",
        "            del a\n",
        "            torch.cuda.synchronize(); \n",
        "            torch.cuda.empty_cache(); \n",
        "    time.sleep(0.25)\n",
        "    gc.collect()\n",
        "    try:\n",
        "        global midas, transform, prediction, input_batch, depth, depth_image, image, sr_image, enhanced_image, img, init,  original_init\n",
        "        del midas, transform, prediction, input_batch, depth, depth_image, image, sr_image, enhanced_image, img, init,  original_init\n",
        "    except NameError:\n",
        "        pass\n",
        "    time.sleep(1)\n",
        "    if v: print(f':recycling_symbol: Cleared memory.  Time taken was {time_format(int(int(time.time()) - stt))}')\n",
        "    new_mem_used = gpu_memory_usage(device)\n",
        "    if v: print(f'VRAM Allocatd: {new_mem_used}mb, VRAM Released: {mem_used - new_mem_used}mb')\n",
        "    if not cuda_availabe:\n",
        "        print(\":WARNING: There is no CUDA device available! Cannot run diffusion models!\")\n",
        "\n",
        "# Basic image display -- God, what is this monster I've spawned? \n",
        "def displayJsImage(b, i, prepend, name, img):\n",
        "    import cv2\n",
        "    from IPython.display import display, Javascript\n",
        "    from google.colab.output import eval_js\n",
        "    from base64 import b64encode\n",
        "    from google.colab import files\n",
        "    import numpy as np\n",
        "    img = np.asarray(img, dtype=np.uint8)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    js = Javascript('''\n",
        "        async function showImage(b, i, prepend, name, image, width, height) {\n",
        "            batchBlock = document.getElementById('batch-block-'+b);\n",
        "            block = document.getElementById('block-'+b+'-'+i)\n",
        "            img = document.getElementById(name);\n",
        "            cont = document.getElementById(name+'_container');\n",
        "\n",
        "            if (batchBlock == null) {\n",
        "                batchBlock = document.createElement('div');\n",
        "                batchBlock.id = 'batch-block-'+b;\n",
        "                batchBlock.style = 'background-color:rgba(0,0,0,0.25);width:auto;margin-bottom:25px;padding:5px;text-align:center;box-shadow: 0px 0px 5px rgba(0,0,0,0.5);';\n",
        "                //batchBlock.innerHTML = '<h2 style=\"background-color:rgba(255,255,255,0.1);margin:0;margin-bottom:5px;padding:4px;text-align:center;text-shadow: 1px 1px rgba(0,0,0,0.35);\">Batch '+b+'</h2>';\n",
        "                if (prepend == 1) {\n",
        "                    document.body.prepend(batchBlock)\n",
        "                } else {\n",
        "                    document.body.appendChild(batchBlock)\n",
        "                }\n",
        "                buttonBt = document.createElement('button');\n",
        "                buttonBt.className = 'collapsible';\n",
        "                buttonBt.style = 'cursor:pointer;width:100%;margin-bottom:5px;border:none;border-bottom:3px solid #999999;padding:5px;text-align:center;font-size:16px;font-weight:bold;color:white;background-color:rgba(155,155,155,0.15);text-shadow: 1px 1px rgba(0,0,0,0.35);transition: all 0.5s;'\n",
        "                buttonBt.innerHTML = 'Batch '+b;\n",
        "                buttonBt.value = 'Batch '+b;\n",
        "                batchBlock.before(buttonBt)\n",
        "            }\n",
        "            if (block == null) {\n",
        "                block = document.createElement('div');\n",
        "                block.id = 'block-'+b+'-'+i;\n",
        "                block.style = 'width: auto;margin-bottom:15px;padding:5px;text-align:center;';\n",
        "                //block.innerHTML = '<h3 style=\"margin:3px;text-align:center;text-shadow: 1px 1px rgba(0,0,0,0.35);\">Iteration '+i+'</h3>';\n",
        "                batchBlock.appendChild(block);\n",
        "                buttonIt = document.createElement('button');\n",
        "                buttonIt.className = 'collapsible';\n",
        "                buttonIt.style = 'cursor:pointer;width:100%;margin-bottom:5px;border:none;border-bottom:3px solid #999999;padding:5px;text-align:center;font-size:16px;font-weight:bold;color:white;background-color:rgba(155,155,155,0.15);text-shadow: 1px 1px rgba(0,0,0,0.35);transition: all 0.5s;'\n",
        "                buttonIt.innerHTML = 'Iteration '+i;\n",
        "                buttonIt.value = 'Iteration '+i;\n",
        "                block.before(buttonIt)\n",
        "            }\n",
        "            if(img == null && cont == null) {\n",
        "                cont = document.createElement('div');\n",
        "                cont.id = name+'_container';\n",
        "                link = document.createElement('a');\n",
        "                link.href = image;\n",
        "                link.target = '_blank';\n",
        "                img = document.createElement('img');\n",
        "                img.id = name;\n",
        "                img.class = \"resultImage\"\n",
        "                cont.style = 'display:inline-block;width:auto;font-size:14px;font-weight:bold;background-color:rgba(0,0,0,0.5);border-radius:5px;padding:2px;margin:2px;box-shadow: 0px 0px 5px rgba(0,0,0,0.5);'\n",
        "                cont.innerHTML = '<p style=\"margin:3px auto;width:180px;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;text-shadow: 1px 1px rgba(0,0,0,0.35);\">'+name+'</p>';\n",
        "                block.appendChild(cont);\n",
        "                cont.appendChild(link);\n",
        "                link.appendChild(img);\n",
        "            }\n",
        "            img.src = image;\n",
        "            img.style = \"margin: 5px; vertical-align: text-top; max-width: 256px; max-height: 512px;\";\n",
        "        }\n",
        "\n",
        "        function debugBase64(base64URL){\n",
        "            var win = window.open();\n",
        "            win.document.write('<iframe src=\"' + base64URL  + '\" frameborder=\"0\" style=\"border:0; top:0px; left:0px; bottom:0px; right:0px; width:100%; height:100%;\" allowfullscreen></iframe>');\n",
        "        }\n",
        "\n",
        "        var coll = document.getElementsByClassName(\"collapsible\");\n",
        "        var i;\n",
        "        for (i = 0; i < coll.length; i++) {\n",
        "\n",
        "            coll[i].addEventListener('mouseover',function(){\n",
        "                this.style.color = 'orange';\n",
        "                this.style.borderBottom = \"3px solid orange\";\n",
        "            })\n",
        "\n",
        "            coll[i].addEventListener('mouseleave',function(){\n",
        "                this.style.color = 'white';\n",
        "                this.style.borderBottom = \"3px solid #999\";\n",
        "            })\n",
        "\n",
        "            coll[i].addEventListener(\"click\", function() {\n",
        "                this.classList.toggle(\"active\");\n",
        "                var content = this.nextElementSibling;\n",
        "                if (content.style.display === \"block\") {\n",
        "                content.style.display = \"none\";\n",
        "                } else {\n",
        "                content.style.display = \"block\";\n",
        "                }\n",
        "            });\n",
        "\n",
        "        }\n",
        "    ''')\n",
        "    height, width = img.shape[:2]\n",
        "    ret, data = cv2.imencode('.png', img)\n",
        "    data = b64encode(data)\n",
        "    data = data.decode()\n",
        "    data = 'data:image/png;base64,' + data\n",
        "    display(js)\n",
        "    eval_js(f'showImage({b}, {i}, {int(prepend)}, \"{name}\", \"{data}\", {width}, {height})')\n",
        "\n",
        "def clearOutputArea(b, i):\n",
        "    from IPython.display import display, Javascript\n",
        "    from google.colab.output import eval_js\n",
        "    js = Javascript('''\n",
        "        function onReady(fn) {\n",
        "            if (document.readyState==='complete' || document.readyState==='interactive') {\n",
        "                setTimeout(fn, 1);\n",
        "            } else {\n",
        "                document.addEventListener(\"DOMContentLoaded\", fn);\n",
        "            }\n",
        "        }\n",
        "        function clearColabOutput(b, i) {\n",
        "            var streams = document.getElementsByClassName('stream');\n",
        "            var dataOutputs = document.getElementsByClassName('display_data');\n",
        "            for(var i = 0; i < streams.length; i++) {\n",
        "                streams[i].innerHTML = '';\n",
        "            }\n",
        "            for(var i = 0; i < dataOutputs.length; i++) {\n",
        "                dataOutputs[i].innerHTML = ''\n",
        "            }\n",
        "        }\n",
        "    ''')\n",
        "    display(js)\n",
        "    eval_js(f'onReady(clearColabOutput({b}, {i}));')\n",
        "\n",
        "def closest_value(input_list, input_value):\n",
        "    difference = lambda input_list : abs(input_list - input_value)\n",
        "    res = min(input_list, key=difference)\n",
        "    return res\n",
        "\n",
        "def printPrompt(prompt, limit=12):\n",
        "    pw = prompt.split(\" \"); i=0; oi=0; pstr = ''\n",
        "    for w in pw:\n",
        "        oi+=1; pstr += f'{w} '\n",
        "        if i is limit or oi is len(pw): print(pstr.strip()); pstr = ''; i = 0; pass\n",
        "        i+=1\n",
        "\n",
        "def sharpenImage(image, samples=1):\n",
        "    import PIL\n",
        "    from PIL import Image, ImageFilter\n",
        "    im = image\n",
        "    for i in range(samples):\n",
        "        im = im.filter(ImageFilter.SHARPEN)\n",
        "    return im\n",
        "\n",
        "def PILSampler(sampling='LANCZOS'):\n",
        "    import PIL\n",
        "    from PIL import Image\n",
        "    if not hasattr(PIL.Image, 'Resampling'): PIL.Image.Resampling = PIL.Image\n",
        "    samplers = {'none': Image.Resampling.NONE,'lanczos': Image.Resampling.LANCZOS,'bilinear': Image.Resampling.LINEAR,'bicubic': Image.Resampling.CUBIC,'box': Image.Resampling.BOX,'hamming': Image.Resampling.HAMMING}\n",
        "    return Image.Resampling(int(sampling)) if sampling.isdigit() and int(sampling)<=5 else ( samplers[sampling.lower()] if samplers.__contains__(sampling.lower()) else Image.Resampling(1) )\n",
        "        \n",
        "\n",
        "def overlayImage(upscaled, source, percent=0.5, sampling='LANCZOS', superres=False):\n",
        "    import PIL\n",
        "    from PIL import Image, ImageFilter\n",
        "    if percent > 1: percent = 1\n",
        "    sampler = PILSampler(sampling)\n",
        "    source_upscaled = source.copy()\n",
        "    print('Upscaled Image:', upscaled)\n",
        "    print('Original Image:', source)\n",
        "    if superres:\n",
        "        source_upscaled = source_upscaled.filter(ImageFilter.SMOOTH_MORE)\n",
        "        source_upscaled_edge = source_upscaled.filter(ImageFilter.EDGE_ENHANCE)\n",
        "        source_upscaled = Image.blend(source_upscaled, source, 0.5)\n",
        "        source_upscaled = Image.blend(source_upscaled, source_upscaled_edge, 0.25)\n",
        "        source_upscaled = source_upscaled.resize((upscaled.size[0]*8, upscaled.size[0]*8), Image.Resampling.LINEAR)\n",
        "        source_upscaled = source_upscaled.filter(ImageFilter.SHARPEN)\n",
        "    source_upscaled = source_upscaled.resize(upscaled.size, sampler)\n",
        "    return Image.blend(upscaled.convert('RGB'), source_upscaled, percent)\n",
        "\n",
        "def getInitImages(path, filters='', verbose=False):\n",
        "    ret_images = []\n",
        "    valid = ['.jpeg','.jpg','.gif','.png']\n",
        "    if filters is not '':\n",
        "        filters = [f.strip() for f in filters.split(',')] if ',' in filters else [filters]\n",
        "    if path.startswith('http://') or path.startswith('https://'):\n",
        "        add = True\n",
        "        if filters is not '':\n",
        "            add = False\n",
        "            for f in filters:\n",
        "                if f in os.path.basename(path):\n",
        "                    add = True\n",
        "        if add:\n",
        "            if verbose: print(f'Found 1 remote image: {path}\\n')\n",
        "            return path\n",
        "        else: \n",
        "            if verbose: print(f'Found no valid image(s)\\n')\n",
        "            return None\n",
        "    if os.path.isdir(path):\n",
        "        try:\n",
        "            images = next(os.walk(path), (None, None, []))[2]\n",
        "            ret_images = []\n",
        "            if images:\n",
        "                if verbose: print(f\"Found {len(images)} image(s) in {path}\\n\")\n",
        "                for img in images:\n",
        "                    ext = os.path.splitext(img)[1]\n",
        "                    if ext in valid:\n",
        "                        add = True\n",
        "                        if filters is not '':\n",
        "                            add = False\n",
        "                            if verbose: print(\"Filtering with:\", filters)\n",
        "                            for f in filters:\n",
        "                                if f in img:\n",
        "                                    add = True\n",
        "                        if add:\n",
        "                            img = f'{path}/{img}'\n",
        "                            if verbose: print(f' -> {img}', defaultprint=True)\n",
        "                            ret_images.append(img)\n",
        "                print('')\n",
        "            if len(ret_images) == 0:\n",
        "                if verbose: print(f'Found no valid image(s)\\n')\n",
        "                return None\n",
        "        except OSError as e:\n",
        "            raise e\n",
        "    elif os.path.isfile(path):\n",
        "        try:\n",
        "            if path.lower().endswith('.txt'):\n",
        "                with open(path, \"r\") as f:\n",
        "                    images = f.read().splitlines()\n",
        "                    if images:\n",
        "                        ret_images = []\n",
        "                        if verbose: print(f\"Found {len(images)} image(s) in {path}\\n\")\n",
        "                        for img in images:\n",
        "                            ext = os.path.splitext(img)[1]\n",
        "                            if ext in valid:\n",
        "                                add = True\n",
        "                                if verbose: print(\"Filtering with:\", filters)\n",
        "                                if filters is not '':\n",
        "                                    add = False\n",
        "                                    for f in filters:\n",
        "                                        if f in img:\n",
        "                                            add = True\n",
        "                                if add:\n",
        "                                    if verbose: print(f' -> {img}', defaultprint=True)\n",
        "                                    ret_images.append(img)\n",
        "                        print('')\n",
        "            else:\n",
        "                ext = os.path.splitext(path)[1]\n",
        "                if ext.lower() in valid:\n",
        "                    add = True\n",
        "                    if filters is not '':\n",
        "                        add = False\n",
        "                        for f in filters:\n",
        "                            if f in os.path.basename(path):\n",
        "                                add = True\n",
        "                    if add:\n",
        "                        if verbose: print(f'Found 1 image: {path}\\n')\n",
        "                        return path\n",
        "                    else:\n",
        "                        if verbose: print(f'Found no valid image(s)\\n')\n",
        "                        return None\n",
        "                else:\n",
        "                    if verbose: print(f'Found no valid image(s)\\n')\n",
        "                    return None\n",
        "        except OSError as e:\n",
        "            raise e\n",
        "    return ret_images\n",
        "\n",
        "def setup_pipes(pipe_type='default', model_id=None, model_cache=None, device='cuda'):\n",
        "    from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline, StableDiffusionInpaintPipeline\n",
        "    if pipe_type is 'lowvram':\n",
        "        clean_env()\n",
        "        print(\":gear: Setting up half-float pipeline...\")\n",
        "        pipe = StableDiffusionPipeline.from_pretrained(model_id, cache_dir=model_cache, torch_dtype=torch.float16, use_auth_token=True).to(device)\n",
        "        del pipe.vae.encoder\n",
        "    elif pipe_type is 'img2img':\n",
        "        clean_env()\n",
        "        print(\":gear: Setting up image-to-image pipeline...\")\n",
        "        pipe = StableDiffusionImg2ImgPipeline.from_pretrained(model_id, cache_dir=model_cache, revision=\"fp16\", torch_dtype=torch.float16, use_auth_token=True).to(device)\n",
        "    elif pipe_type is 'inpaint':\n",
        "        clean_env()\n",
        "        print(\":gear: Setting up inpainting image-to-image pipeline...\")\n",
        "        pipe = StableDiffusionInpaintPipeline.from_pretrained(model_id, cache_dir=model_cache, revision=\"fp16\", torch_dtype=torch.float16, use_auth_token=True).to(device)\n",
        "    elif pipe_type is 'default':\n",
        "        clean_env()\n",
        "        print(\":gear: Setting up default full-float text-to-image pipeline...\")\n",
        "        pipe = StableDiffusionPipeline.from_pretrained(model_id, cache_dir=model_cache, use_auth_token=True).to(device)\n",
        "    return pipe\n",
        "\n",
        "def cache_pipes(pipe_type, model_id, model_cache, pipe_cache, device='cuda'):\n",
        "    global RECACHE_PIPES\n",
        "    import joblib, os, gc\n",
        "    from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline, StableDiffusionInpaintPipeline\n",
        "    \n",
        "    if pipe_type is 'lowvram':\n",
        "        if not os.path.exists(f'{pipe_cache}/LOW_VRAM_PIPE.obj') or RECACHE_PIPES:\n",
        "            joblib.dump(StableDiffusionPipeline.from_pretrained(model_id, cache_dir=model_cache, torch_dtype=torch.float16, use_auth_token=True).to(device), f'{pipe_cache}/LOW_VRAM_PIPE.obj')\n",
        "            if os.path.exists(f'{pipe_cache}/LOW_VRAM_PIPE.obj'):\n",
        "                print('Cached pipe:', f'{pipe_cache}/LOW_VRAM_PIPE.obj')\n",
        "            gc.collect()\n",
        "        pipe = joblib.load(f'{pipe_cache}/LOW_VRAM_PIPE.obj')\n",
        "        del pipe.vae.encoder\n",
        "        pipe.model_id = MODEL_ID\n",
        "        return pipe\n",
        "    if pipe_type is 'img2img':\n",
        "        if not os.path.exists(f'{pipe_cache}/IMG2IMG_PIPE.obj') or RECACHE_PIPES:\n",
        "            joblib.dump(StableDiffusionImg2ImgPipeline.from_pretrained(model_id, cache_dir=model_cache, revision=\"fp16\", torch_dtype=torch.float16, use_auth_token=True).to(device), f'{pipe_cache}/IMG2IMG_PIPE.obj')\n",
        "            if os.path.exists(f'{pipe_cache}/IMG2IMG_PIPE.obj'):\n",
        "                print('Cached pipe:', f'{pipe_cache}/IMG2IMG_PIPE.obj')\n",
        "            gc.collect()\n",
        "        pipe = joblib.load(f'{pipe_cache}/IMG2IMG_PIPE.obj')\n",
        "        pipe.model_id = MODEL_ID\n",
        "        return pipe\n",
        "    if pipe_type is 'inpaint':\n",
        "        if not os.path.exists(f'{pipe_cache}/INPAINT_PIPE.obj') or RECACHE_PIPES:\n",
        "            joblib.dump(StableDiffusionInpaintPipeline.from_pretrained(model_id, cache_dir=model_cache, revision=\"fp16\", torch_dtype=torch.float16, use_auth_token=True).to(device), f'{pipe_cache}/INPAINT_PIPE.obj')\n",
        "            if os.path.exists(f'{pipe_cache}/INPAINT_PIPE.obj'):\n",
        "                print('Cached pipe:', f'{pipe_cache}/INPAINT_PIPE.obj')\n",
        "            gc.collect()\n",
        "        pipe = joblib.load(f'{pipe_cache}/INPAINT_PIPE.obj')\n",
        "        pipe.model_id = MODEL_ID\n",
        "        return pipe\n",
        "    if pipe_type is 'default':\n",
        "        if not os.path.exists(f'{pipe_cache}/DEFAULT.obj') or RECACHE_PIPES:\n",
        "            joblib.dump(StableDiffusionPipeline.from_pretrained(model_id, cache_dir=model_cache, use_auth_token=True).to(device), f'{pipe_cache}/DEFAULT_PIPE.obj')\n",
        "            if os.path.exists(f'{pipe_cache}/DEFAULT.obj'):\n",
        "                print('Cached pipe:', f'{pipe_cache}/DEFAULT.obj')\n",
        "            gc.collect()\n",
        "        pipe = joblib.load(f'{pipe_cache}/DEFAULT_PIPE.obj')\n",
        "        pipe.model_id = MODEL_ID\n",
        "        return pipe\n",
        "    return None\n",
        "\n",
        "def safetyCheckerDummy(images, **kwargs):\n",
        "    return images, False\n",
        "\n",
        "def preprocess(image):\n",
        "    import PIL\n",
        "    import numpy as np\n",
        "    w, h = image.size\n",
        "    w, h = map(lambda x: x - x % 32, (w, h))  # resize to integer multiple of 32\n",
        "    image = image.resize((w, h), resample=PIL.Image.LANCZOS)\n",
        "    image = np.array(image).astype(np.float32) / 255.0\n",
        "    image = image[None].transpose(0, 3, 1, 2)\n",
        "    image = torch.from_numpy(image)\n",
        "    return 2.0 * image - 1.0\n",
        "\n",
        "def move_files(source, destination):\n",
        "    for src_dir, dirs, files in os.walk(source):\n",
        "        dst_dir = src_dir.replace(source, destination)\n",
        "        if not os.path.exists(dst_dir):\n",
        "            os.mkdir(dst_dir)\n",
        "        for file_ in files:\n",
        "            src_file = os.path.join(src_dir, file_)\n",
        "            dst_file = os.path.join(dst_dir, file_)\n",
        "            if os.path.exists(dst_file):\n",
        "                os.remove(dst_file)\n",
        "            shutil.copy(src_file, dst_dir)\n",
        "\n",
        "def download_model(model_id, redownload=False):\n",
        "    import os, shutil\n",
        "    global moved_from_cache, last_model\n",
        "    rep = ['CompVis/','hakurei/']\n",
        "    localf = model_id\n",
        "    for r in rep:\n",
        "        localf = model_id.replace(r, '')\n",
        "    model = f'{model_cache}/{localf}'\n",
        "    if redownload and moved_from_cache:\n",
        "        moved_from_cache = False\n",
        "    drive_model = f'{drive_model_cache}/{localf}'\n",
        "    if USE_DRIVE_FOR_MODELS and not USE_DRIVE_FOR_LOCAL_COPIES and not moved_from_cache and not redownload:\n",
        "        print(\":open_file_folder: Moving model files to model cache from drive cache ...\")\n",
        "        if not os.path.exists(model_cache):\n",
        "            os.makedirs(model_cache)\n",
        "        if os.path.exists(drive_model) or len(os.listdir(drive_model_cache)) > 0:\n",
        "            try:\n",
        "                move_files(drive_model_cache, model_cache)\n",
        "                print(\":check_mark_button: Move complete.\")\n",
        "                redownload = False\n",
        "                moved_from_cache = True\n",
        "            except OSError as e:\n",
        "                redownload = True\n",
        "                print(\"Uneable to move model cache from:\", drive_model_cache)\n",
        "                pass\n",
        "        else:\n",
        "            print(f':WARNING: \\'{model_id}\\' doesn\\'t exist in \\'{drive_model_cache}\\', or any other model weights or models!')\n",
        "            redownload = True\n",
        "    if redownload:\n",
        "        if os.path.exists(model):\n",
        "            shutil.rmtree(model)\n",
        "        os.chdir(model_cache)\n",
        "        print(\":hourglass_not_done: Downloading model weights for:\", model_id)\n",
        "        print(subprocess.run(['git', 'clone', f'https://{hu}:{ht}@huggingface.co/{model_id}'], stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "        print(\":check_mark_button: Downloaded complete.\")\n",
        "        os.chdir(STABLE_DIFFUSION_WORKDIR)\n",
        "    if USE_DRIVE_FOR_MODELS and not USE_DRIVE_FOR_LOCAL_COPIES and not moved_from_cache:\n",
        "        print(\":open_file_folder: Moving model files to drive cache ...\")\n",
        "        if not os.path.exists(drive_model_cache):\n",
        "            os.makedirs(drive_model_cache)\n",
        "        if os.path.exists(model) or len(os.listdir(model_cache)) > 0:\n",
        "            move_files(model_cache, drive_model_cache)\n",
        "            print(\":check_mark_button: Move complete.\")\n",
        "        else:\n",
        "            print(f':WARNING: \\'{model_id}\\' doesn\\'t exist in \\'{model_cache}\\', or any other model weights or models!')\n",
        "        moved_from_cache = True\n",
        "\n",
        "# SETUP DEPENDENCIES\n",
        "print(\"\\nStarting Installation Processess.\\nThis should take approximately one eternity...\\n\")\n",
        "\n",
        "try:\n",
        "  with fetch_bytes('https://raw.githubusercontent.com/WASasquatch/easydiffusion/main/key.txt') as f:\n",
        "    k = f.read().decode('utf-8').split(':'); hu = k[0].strip(); ht = k[1].strip()\n",
        "except OSError as e:\n",
        "  raise e\n",
        "\n",
        "try:\n",
        "\n",
        "    # Install psutil\n",
        "    if 'psutil' in packages():\n",
        "        print(':check_mark_button: \\'psutil\\' already installed.\\n')\n",
        "    else:\n",
        "        print(':hourglass_not_done: Installing \\'psutil\\' ...')\n",
        "        print(subprocess.run(['pip', '-q', 'install', 'psutil'], stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "        print(':check_mark_button: \\'psutil\\' installed.\\n')\n",
        "    import psutil\n",
        "\n",
        "    if 'joblib' in packages():\n",
        "        print(':check_mark_button: \\'joblib\\' alrleady installed.\\n')\n",
        "    else:\n",
        "        print(':hourglass_not_done: Installing \\'joblib\\' ...')\n",
        "        print(subprocess.run(['pip', '-q', 'install', 'joblib'], stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "        print(':check_mark_button: \\'joblib\\' installed.\\n')\n",
        "    import joblib\n",
        "    from joblib import Memory\n",
        "    cache_dir = f'{STABLE_DIFFUSION_WORKDIR}/cache'\n",
        "\n",
        "    # Install Shutup\n",
        "    if 'shutup' not in packages():\n",
        "        subprocess.run(['pip', '-q', 'install', 'shutup'], stdout=subprocess.DEVNULL)\n",
        "    import shutup; \n",
        "    if SUPPRESS_WARNINGS: \n",
        "        shutup.please()\n",
        "\n",
        "    import warnings\n",
        "    if SUPPRESS_WARNINGS:\n",
        "        warnings.filterwarnings(\"ignore\", category=UserWarning) \n",
        "    \n",
        "    #rint(subprocess.run(['git', 'lfs', 'install'], stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "    #os.environ['GIT_LFS_SKIP_SMUDGE'] = \"0\"\n",
        "\n",
        "    # This will take a while\n",
        "\n",
        "    # Install Diffusers\n",
        "    if 'diffusers' not in packages():\n",
        "        print(':hourglass_not_done: Installing \\'diffusers\\' ...')\n",
        "        try:\n",
        "            subprocess.run(['pip', '-q', 'install', '-U', 'git+https://github.com/huggingface/diffusers.git'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "        except OSError as e:\n",
        "            raise e\n",
        "        finally:\n",
        "            if 'diffusers' in packages():\n",
        "                print(':check_mark_button: \\'diffusers\\' installed.\\n')\n",
        "            else:\n",
        "                raise OSError(':warning: \\'diffusers\\' could not be installed.\\n')\n",
        "    else:\n",
        "        print(':check_mark_button: \\'diffusers\\' already installed.\\n')\n",
        "        \n",
        "    # Patch Safety Checker\n",
        "    if os.path.exists('/usr/local/lib/python3.7/dist-packages/diffusers/pipelines/stable_diffusion/safety_checker.py'):\n",
        "        os.chdir(STABLE_DIFFUSION_WORKDIR)\n",
        "        wgeto('https://raw.githubusercontent.com/WASasquatch/easydiffusion/main/replacements/diffusers/pipelines/stable_diffusion/safety_checker.py', 'safety_checker.py')\n",
        "        shutil.copy('safety_checker.py', '/usr/local/lib/python3.7/dist-packages/diffusers/pipelines/stable_diffusion/')\n",
        "\n",
        "    # Patch Stable Diffusion Pipelines\n",
        "    if os.path.exists('/usr/local/lib/python3.7/dist-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py'):\n",
        "        os.chdir(STABLE_DIFFUSION_WORKDIR)\n",
        "        wgeto('https://raw.githubusercontent.com/WASasquatch/easydiffusion/main/replacements/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py', 'pipeline_stable_diffusion.py')\n",
        "        shutil.copy('pipeline_stable_diffusion.py', '/usr/local/lib/python3.7/dist-packages/diffusers/pipelines/stable_diffusion/')\n",
        "\n",
        "    if os.path.exists('/usr/local/lib/python3.7/dist-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_img2img.py'):\n",
        "        os.chdir(STABLE_DIFFUSION_WORKDIR)\n",
        "        wgeto('https://raw.githubusercontent.com/WASasquatch/easydiffusion/main/replacements/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_img2img.py', 'pipeline_stable_diffusion_img2img.py')\n",
        "        shutil.copy('pipeline_stable_diffusion_img2img.py', '/usr/local/lib/python3.7/dist-packages/diffusers/pipelines/stable_diffusion/')\n",
        "\n",
        "    if os.path.exists('/usr/local/lib/python3.7/dist-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_inpaint.py'):\n",
        "        os.chdir(STABLE_DIFFUSION_WORKDIR)\n",
        "        wgeto('https://raw.githubusercontent.com/WASasquatch/easydiffusion/main/replacements/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_inpaint.py', 'pipeline_stable_diffusion_inpaint.py')\n",
        "        shutil.copy('pipeline_stable_diffusion_inpaint.py', '/usr/local/lib/python3.7/dist-packages/diffusers/pipelines/stable_diffusion/')\n",
        "\n",
        "    if 'transformers' not in packages():\n",
        "        print(':hourglass_not_done: Installing \\'transformers\\' ...')\n",
        "        res = None\n",
        "        try:\n",
        "            res = subprocess.run(['pip', '-q', 'install', 'transformers', 'sentencepiece'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "        except OSError as e:\n",
        "            raise e\n",
        "        finally:\n",
        "            if ['transformers','sentencepiece'] in packages():\n",
        "                print(':check_mark_button: \\'transformers\\' installed.\\n')\n",
        "            else:\n",
        "                print(':warning: \\'transformers\\' could not be installed.\\n')\n",
        "    else:\n",
        "        print(':check_mark_button: \\'transformers\\' already installed.\\n')\n",
        "\n",
        "    print(':hourglass_not_done: Installing pytorch dependencies...')\n",
        "    res = ''\n",
        "    if 'pytorch-pretrained-bert' not in packages():\n",
        "        res += subprocess.run(['pip', '-q', 'install', 'pytorch-pretrained-bert'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    if 'spacy' not in packages():\n",
        "        res += subprocess.run(['pip', '-q', 'install', 'spacy'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    if 'ftfy' not in packages():\n",
        "        res += subprocess.run(['pip', '-q', 'install', 'ftfy'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    if res and res.strip() is not '':\n",
        "        print(res)\n",
        "    if ['pytorch-pretrained-bert', 'spacy', 'ftfy'] in packages():\n",
        "        print(':check_mark_button: pytorch dependencies installed.\\n')\n",
        "\n",
        "    if 'spacy' not in packages():\n",
        "        print(':hourglass_not_done: Setting up \\'spacy\\' ...\\n')\n",
        "        if SUPPRESS_WARNINGS:\n",
        "            subprocess.run(['python', '-m', 'spacy', 'download', 'en'], stdout=subprocess.DEVNULL)\n",
        "        else:\n",
        "            print(subprocess.run(['python', '-m', 'spacy', 'download', 'en'], stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "        print(':check_mark_button: \\'spacy\\' setup complete.\\n')\n",
        "    else:\n",
        "        print(':check_mark_button: \\'spacy\\' already installed.\\n')\n",
        "\n",
        "    if 'scipy' not in packages():\n",
        "        print(':hourglass_not_done: Installing \\'scipy\\' ...')\n",
        "        res = None\n",
        "        try:\n",
        "            res = subprocess.run(['pip', '-q', 'install', 'scipy'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "        except OSError as e:\n",
        "            raise e\n",
        "        finally:\n",
        "            if 'scipy' in packages():\n",
        "                print(':check_mark_button: \\'scipy\\' installed.\\n')\n",
        "            else:\n",
        "                print(':warning: \\'scipy\\' could not be installed.\\n')\n",
        "    else:\n",
        "        print(':check_mark_button: \\'scipy\\' already installed.\\n')\n",
        "\n",
        "    if not os.path.exists(f'{STABLE_DIFFUSION_WORKDIR}/k-diffusion'):\n",
        "        print(':hourglass_not_done: Downloading \\'k-diffusers\\' ...')\n",
        "        print(subprocess.run(['git', 'clone', '--quiet', '--recursive', 'https://github.com/crowsonkb/k-diffusion.git'], stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "    else:\n",
        "        print(':check_mark_button: \\'k-diffusers\\' downloaded.\\n')\n",
        "\n",
        "    print(':globe_with_meridians: Logging into HuggingFace API...')\n",
        "    subprocess.run(['git', 'config', '--global', 'credential.helper', 'store'], stdout=subprocess.DEVNULL)\n",
        "    left_of_pipe = subprocess.Popen([\"echo\", ht], stdout=subprocess.PIPE)\n",
        "    right_of_pipe = subprocess.run(['huggingface-cli', 'login'], stdin=left_of_pipe.stdout, stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(right_of_pipe)\n",
        "\n",
        "    # Optional Installers\n",
        "\n",
        "    opts = {\n",
        "        'ESRGAN_INSTALLED': False,\n",
        "        'CODEFORMER_INSTALLED': False,\n",
        "    }\n",
        "        \n",
        "    def install_realesrgan():\n",
        "        global opts\n",
        "        print(\"\\n:hourglass_not_done: Installing Real-ESRGAN\")\n",
        "        res = ''\n",
        "        if not os.path.exists(f'{STABLE_DIFFUSION_WORKDIR}/Real-ESRGAN'):\n",
        "            res += subprocess.run(['git', 'clone', '--quiet', 'https://github.com/sberbank-ai/Real-ESRGAN'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "            res += subprocess.run(['pip', '-q', 'install', '-r', 'Real-ESRGAN/requirements.txt'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "            wget(\"https://huggingface.co/datasets/db88/Enhanced_ESRGAN/resolve/main/RealESRGAN_x2.pth\", \"Real-ESRGAN/weights/\")\n",
        "            wget(\"https://huggingface.co/datasets/db88/Enhanced_ESRGAN/resolve/main/RealESRGAN_x4.pth\", \"Real-ESRGAN/weights/\")\n",
        "            wget(\"https://huggingface.co/datasets/db88/Enhanced_ESRGAN/resolve/main/RealESRGAN_x8.pth\", \"Real-ESRGAN/weights/\")\n",
        "        if res.strip() is not '':\n",
        "            print(res)\n",
        "        opts['ESRGAN_INSTALLED'] = True\n",
        "        print(\":check_mark_button: Real-ESRGAN installed!\\n\")\n",
        "        \n",
        "    def upscale(image, scale, device='cuda'):\n",
        "        os.chdir(f'{STABLE_DIFFUSION_WORKDIR}/Real-ESRGAN')\n",
        "        from RealESRGAN import RealESRGAN\n",
        "        device = torch.device(device)\n",
        "        model = RealESRGAN(device, scale = scale)\n",
        "        model.load_weights(f'weights/RealESRGAN_x{scale}.pth')\n",
        "        sr_image = model.predict(np.array(image))\n",
        "        del model, device\n",
        "        os.chdir(f'{STABLE_DIFFUSION_WORKDIR}')\n",
        "        return sr_image\n",
        "\n",
        "    def install_codeformer():\n",
        "        global opts\n",
        "        print(\":hourglass_not_done: Downloading CodeFormer...\\n\")\n",
        "        res = ''\n",
        "        if not os.path.exists(f'{STABLE_DIFFUSION_WORKDIR}/CodeFormer'):\n",
        "            os.chdir(STABLE_DIFFUSION_WORKDIR)\n",
        "            res += subprocess.run(['git', 'clone', '--quiet', 'https://github.com/sczhou/CodeFormer.git'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "\n",
        "        os.chdir(f'{STABLE_DIFFUSION_WORKDIR}/CodeFormer')\n",
        "        res += subprocess.run(['pip', '-q', 'install', '-r', 'requirements.txt'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "        # Install basicsr\n",
        "        if SUPPRESS_WARNINGS:\n",
        "            subprocess.run(['python', 'basicsr/setup.py', 'develop'], stdout=subprocess.DEVNULL)\n",
        "        else:\n",
        "            res += subprocess.run(['python', 'basicsr/setup.py', 'develop'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "\n",
        "        # Download the pre-trained model\n",
        "        if SUPPRESS_WARNINGS:\n",
        "            subprocess.run(['python', 'scripts/download_pretrained_models.py', 'facelib'], stdout=subprocess.DEVNULL)\n",
        "            subprocess.run(['python', 'scripts/download_pretrained_models.py', 'CodeFormer'], stdout=subprocess.DEVNULL)\n",
        "        else: \n",
        "            res += subprocess.run(['python', 'scripts/download_pretrained_models.py', 'facelib'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "            res += subprocess.run(['python', 'scripts/download_pretrained_models.py', 'CodeFormer'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "        if res.strip() is not '':\n",
        "            print(res)\n",
        "        os.makedirs('temp', exist_ok=True)\n",
        "        os.makedirs('results', exist_ok=True)\n",
        "        os.chdir(STABLE_DIFFUSION_WORKDIR)\n",
        "        opts['CODEFORMER_INSTALLED'] = True\n",
        "        print(\":check_mark_button: CodeFormer downloaded!\\n\")\n",
        "\n",
        "    # Colab Param Scraper\n",
        "    try:\n",
        "        from colabparamscraper.paramscraper import paramScraper\n",
        "    except ImportError:\n",
        "        print(\":hourglass_not_done: Installing Colab paramScraper ...\")\n",
        "        res = ''\n",
        "        res += subprocess.run(['git', 'clone', '--quiet', 'https://github.com/WASasquatch/colabparamscraper'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "        if res.strip() is not '':\n",
        "            print(res)\n",
        "    finally:\n",
        "        from colabparamscraper.paramscraper import paramScraper\n",
        "        print(\":check_mark_button: Colab paramScraper installed!\\n\")\n",
        "    \n",
        "    # Noodle Soup prompts\n",
        "    try:\n",
        "        import nsp_pantry\n",
        "    except ImportError:\n",
        "        if not os.path.exists('nsp_pantry.py'):\n",
        "            print(\":hourglass_not_done: Installing Noodle Soup Prompts...\")\n",
        "            wget('https://raw.githubusercontent.com/WASasquatch/noodle-soup-prompts/main/nsp_pantry.py', './')\n",
        "    finally:\n",
        "        import nsp_pantry\n",
        "        from nsp_pantry import nsp_parse\n",
        "\n",
        "    if nsp_parse:\n",
        "        print(\"\\r\\r:check_mark_button: \\33[32mNSP installed successfuly.\\33[0m \\x1B[3mMmm... Noodle Soup.\\x1B[0m\\n\")\n",
        "\n",
        "except OSError as e:\n",
        "    raise e\n",
        "except BaseException as e:\n",
        "    raise e\n",
        "finally:\n",
        "    if CLEAR_SETUP_LOG: clear()\n",
        "    print(f\"\\n--[ :confetti_ball::party_popper: \\033[1m\\33[32mIdun.AI Setup Complete\\33[0m :party_popper::confetti_ball: ]--\")\n",
        "\n",
        "from PIL import Image, ImageFilter\n",
        "from io import BytesIO\n",
        "import random, pprint, requests\n",
        "from contextlib import contextmanager, nullcontext\n",
        "from torch import autocast\n",
        "from diffusers import PNDMScheduler, LMSDiscreteScheduler, DDIMScheduler, DDPMScheduler\n",
        "from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline, StableDiffusionInpaintPipeline\n",
        "from IPython.display import clear_output\n",
        "import numpy as np\n",
        "\n",
        " # Styles\n",
        "style = {\n",
        "\t\"Anime (Japanese Animation Inspired)\": \"Kodomo Style, MOE Anime Style, Ecchi, highly detailed, shadows and highlights, Vibrant Color Scheme, trending on ArtStation, Pixiv --Watermark\",\n",
        "\t\"Cartoon (Matt Groening)\": \"Cartoon, American Animation, The Simpsons Art Style, in the Style of Matt Groening and Chris (Simpsons artist), Flat Colors, Lined Cartoon Art, High Resolution, High Quality, Gracie Films --Watermark, border, frame, image compression\",\n",
        "    \"Cartoon (Seth McFarlane)\": \"Cartoon, American Animation, Family Guy ARt Style, in the Style of Seth MacFarlane and Butch Hartman, Flat Colors, Lined Cartoon Art, High Resolution, High Quality, Underdog Productions Animation, Fuzzy Door Productions Animation --Watermark, border, frame, image compression\",\n",
        "    \"Cosmic (Space Art Style)\": \"Science Fiction, Scifi Theme, Cyberpunk, Outer Space, Deep Space, Cosmic Style, Starfield, Nebulas and distant galeies, Astro, Digital Illustration, In the Style of Gabriel Björk Stiernström and John Berkey --Watermark, image compression, film grain, noise\",\n",
        "    \"Cyberpunk\": \"Cyberpunk, Outer Space, Hyper Realistic, ArtStation, CGSociety, Neon lights, Cinematic Lighting, Volumetric Lighting, Realistic Surrealism, Style of Thomas Kinkade and Soufiane Idrassi --Watermark\",\n",
        "\t\"Dragan (Andrzej Dragan Inspired)\": \"photorealistic color scheme, digital photography, dragan effect, dragan style, high contrast detail, dirty, gritty, urban, color photo --Watermark\",\n",
        "\t\"Dystopian (Bleak)\": \"Photorealistic, Highly Detailed Illustration, Beautiful Aesthetic, Digitial Painting, Dystopian, Moody Atmosphere, Bleak Looking, Eartly, Terrestrial Society, Natural Color Scheme, Hopeless World, Earthborn, Salvaged Materials, Recycled World, Volumetric Lighting, Cinematic, by Ilya Kuvshinov and Aaron Jasinski --Watermark, Border, Frame, Noise, Bloody Skin\",\n",
        "    \"Exopunk (Extreterrestrial Cyberpunk Inspired)\": \"Extraterrestrial Exopunk, Psychedelic Zaha Hadid, Outer Space, Exoplanet, Alien Technology, Colored Lights, Volumetric Lighting, Cinematic Lighting, Atmospheric, Surrealism, Style of Dangiuz and Soufiane Idrassi --Watermark, Noise, Compression\",\n",
        "\t\"Futuristic Scifi (Science Fiction Inspired)\": \"Photorealistic, Highly Detailed Illustration, Digitial Painting, Science Fiction, Scifi, Advanced Technology, Intricately Designed, Machinery, AI Artificial Intelligence, Androids, Deep Space, Energy Shields, Z-Space, Post-Human, Quantum, Utopian, Volumetric Lighting, Cinematic, by Ilya Kuvshinov and Aaron Jasinski --Watermark, Border, Frame, Noise\",\n",
        "    \"Gallic (Inspired by Celtic, Gallic, and Gaulish Cultures)\": \"Photorealistic, Digital Art, High Qualtiy, Dark Color Schemes, Gaulish and Celtic Theme, Murky and Atmospheric, Cinematic Lighting, Volumetrics, God Rays, Light Shafts, Particles and Dust in the Air, Elaborate Gallic Designs --Watermark, Border, Frame\",\n",
        "    \"Gigercraft (H.R. Giger and H.P. Lovecraft Inspired)\": \"Sience Fiction, Scifi Theme, Neutral Color Scheme, Organic Growth, Segmentation, Glistening, Wet Surfaces, Dark Atmosphere, Cinematic Lighting, Volumetric Lighting, Extraterrestrial, in the Style of H.R. Giger and H. P. Lovecraft and Dariusz Zawadzki -- Watermark, Image Compression, Film Grain, Noise\",\n",
        "    \"Ink & Watercolor (Zhang QuanZong Inspired)\": \"Photorealistic, Hyperrealism, Highly Detailed, Shaded Colors, Poetic Painting, Ink and Watercolor Influence, Ink and Watercolour, by Zhang QuanZong and Jing Hao (Hongguzi), High Quality, HD, Ornate and Elaborate Inkwork, Vibrant Colors --Watermark, Image Compression, Noise, Western art\",\n",
        "    \"Macabre (Midjourney Inspired)\": \"dark color scheme, grunge macabre aesthetic smudging style dark atmosphere bokeh evil painting --Watermark\",\n",
        "\t\"Medieval\": \"Photorealistic, Medieval Theme, Dark nature aesthetic, Atmospheric Lighting, Ambient Lighting, Volumetric Lighting, lightly smokey air, Archaic, Gothic Architecture, Feudal Theme, Anglo-Saxon Theme --Watermark, Image Compression, Noise, Film Graine\",\n",
        "    \"Modern Religious (Christian Art Inspired)\": \"modern, highly detailed, elaborate, prestine clarity holy aesthetic digital painting heavenly atmosphere bokeh ethereal painting divine hazey --Watermark\",\n",
        "\t\"Oil (Impressionist)\": \"Oil Painting, Brush Strokes, Canvas Texture, Textured Paint, Range of Color, Oil Canvas Style, Grainy Brush Strokes, Large Brush Strokes, Impressionist --Watermark\",\n",
        "\t\"Oil (Naturalist)\": \"Naturalistic Style, Realistic Oil Painting, Highly Detailed, Realism,  Fine Art, Chiaroscuro Style, Campitura --Watermark\",\n",
        "\t\"Organic Ornate (Elaborate Decorative Style)\": \"Photorealistic, 3D Matte, by ellen jewett, tomasz alen kopera and Justin Gerard, symmetrical features, ominous, solemn, magical realism, texture, intricate, ornate, royally decorated, Halo, Gilding, Gilded, whirling smoke, particles, gold adornements, white splendid fabric, radiant colors, artstation, volumetric lighting, micro details, 3d sculpture, ray tracing --Watermark, Picture Frame\",\n",
        "    \"Pen & Pencil\": \"hyperrealistic sketch, high relief sketch, detailed lines, pencil lines, realism, shading lines, pen on paper, well defined --Watermark\",\n",
        "\t\"Photorealistic\": \"photograph, realistic, photorealistic, real life, photography, bokeh, lens attenuation, chromatic aberration, realistic color scheme, by Getty Images --Watermark, Brushwork, Style of Drawing, Style of Painting\",\n",
        "\t\"Post-Apocalyptic (Wasteland-like Inspired)\": \"Post-Apocalyptic, Overgrown World, Wasteland, Ruins and Debris, Naturalist Color Scheme, Volumetric Lighting, Cinematic Lighting, Atmospheric, Style of James Chadderton, and Diego Matiz --Watermark\",\n",
        "\t\"Pop Art (High Contrast Color Mixing)\": \"Pop Art, Vivid Color Scheme, Stylized Color, Abstract Brushwork, Digital Painting, Pop culture, Surreal, Highly Detailed, Punky, Splat, Pow, Bam --Watermark\",\n",
        "\t\"Prismatic Universe (Vivid Rainbow Colors)\": \"Photorealistic, Digital Painting, Quantum Universe, Quantum Energy, Made out of Prismatic Crystals, Chromatic Aberration, Prism Colors, Emitting Energy, Celestial, Etherreal, by Ilya Kuvshinov and Ellen Jewett, Prism Color Scheme, Volumetric Lighting, Cinematic, High Quality, High Resolution, Light Shafts, God Rays --Watermark, Image Compression, Noise, Frame, Border\",\n",
        "    \"Regal Imperial (Decorative Royal Accents)\": \"Imperial Regal Style, Gilded by Golden Wheat and Barley, Adorned in Gemstones, Gold and Silver Accent, 3D Matte, by Ilya Kuvshinov, Eve Ventrue, and Aaron Jasinski, ArtStation, CGSociety, elaborate detailed adornment, royal accent, regal features, atmospheric, cinematic, volumetric lighting, supple complexion --Watermark\",\n",
        "    \"Trippy (Psychedelic Art Inspired)\": \"Photorealistic Mandelbrot Set, Beautiful 3D Fractals, Fractalizations, 3d smooth Kaleidoscopes, Realistic Psychedelic Patterns --Watermark, Image Compression, Film Grain, Noise\",\n",
        "    \"Vivid Disco (Glamour in Dynamic Colors)\": \"Photorealistic, Vivid Disco Color Scheme, Color Mixing, High Contrast, Highly Detailed, Poppy, Lens Flares, Shine, Sparkle, Glitter, Style of Ilya Kuvshinov --Watermark, Compression, Noise\"\n",
        "}\n",
        "\n",
        "# Setup param scraper\n",
        "scraper = paramScraper(settings_template, globals())\n",
        "scraper.scrape('setup')\n",
        "\n",
        "last_pipe_type = None\n",
        "last_model_type = None\n",
        "\n",
        "SAVE_SETTING_FILE = True\n",
        "LOAD_SETTINGS_FILE = '' #@param{type:'string'}\n",
        "#@markdown <font size=\"3\">Load a Idun.AI Settings file to ***bypass*** the settings below. Will use the file settings to perform a run.</font>\n",
        "\n",
        "#@markdown ### **Prompt Setup**\n",
        "PROMPT = \"A beautiful alluring woman sits upon a old cobblestone well, in a Vivid Color Scheme, by Ilya Kuvshinov, Photorealistic, Digital Painting, Cinematic Lighting, Light Shafts\" #@param {type:'string'}\n",
        "PROMPT_STYLE = 'None' #@param['None', 'Anime (Japanese Animation Inspired)', 'Cartoon (Matt Groening)', 'Cartoon (Seth McFarlane)', 'Cosmic (Space Art Style)', 'Cyberpunk', 'Dragan (Andrzej Dragan Inspired)', 'Dystopian (Bleak)', 'Exopunk (Extreterrestrial Cyberpunk Inspired)', 'Futuristic Scifi (Science Fiction Inspired)', 'Gallic (Inspired by Celtic, Gallic, and Gaulish Cultures)', 'Gigercraft (H.R. Giger and H.P. Lovecraft Inspired)', 'Ink & Watercolor (Zhang QuanZong Inspired)', 'Macabre (Midjourney Inspired)', 'Medieval (Medieval Theme Inspired)', 'Modern Religious (Christian Art Inspired)', 'Oil (Impressionist)', 'Oil (Naturalist)', 'Organic Ornate (Elaborate Decorative Style)', 'Pen & Pencil', 'Photorealistic', 'Post-Apocalyptic (Wasteland-like Inspired)', 'Pop Art (High Contrast Color Mixing)', 'Prismatic Universe (Vivid Rainbow Colors)', 'Regal Imperial (Decorative Royal Accents)', 'Trippy (Psychedelic Art Inspired)', 'Vivid Disco (Glamour in Dynamic Colors)']\n",
        "#@markdown <font size=\"3\">Apply a style to your prompt. Focus on the prompt, not the style!\n",
        "\n",
        "#@markdown ### **Diffusion Settings**\n",
        "MODEL_ID = 'CompVis/stable-diffusion-v1-4' #@param [\"CompVis/stable-diffusion-v1-4\", \"CompVis/stable-diffusion-v1-3\",\"CompVis/stable-diffusion-v1-2\",\"CompVis/stable-diffusion-v1-1\",\"hakurei/waifu-diffusion\"]\n",
        "WIDTH = 512 #@param {type:\"slider\", min:256, max:1280, step:64}\n",
        "HEIGHT = 512 #@param {type:\"slider\", min:256, max:1280, step:64}\n",
        "SCALE = 13.5 #param {type:\"slider\", min:0, max:25, step:0.1}\n",
        "NUM_ITERS = 5 #param {type:\"slider\", min:1, max:1000, step:1} \n",
        "#@markdown <font size=\"3\">Number of iterations for a given prompt or init image.</font>\n",
        "IMAGES_FOLDER = \"MyImagination\" #@param {type: 'string'}\n",
        "#@markdown <font size=\"3\">**Full Path:** `/content/Stable_Diffusion/images_out` - Click the folder icon on the left to access files</font>\n",
        "\n",
        "PROMPT_FILE = '' \n",
        "\n",
        "NEW_NSP_ON_ITERATION = True\n",
        "INIT_IMAGE = \"\"\n",
        "INIT_MASK = \"\" \n",
        "INIT_FILTERS = ''\n",
        "INIT_SCALE = 0.5 \n",
        "RECURSIVE_EVOLUTION = False \n",
        "\n",
        "REDOWNLOAD_MODEL = False\n",
        "SAMPLER = 'PNDM'\n",
        "DDIM_ETA = 0.65 \n",
        "STEPS = 30 \n",
        "SEED = 0 \n",
        "MAX_SEED = 'system_max' \n",
        "INCREMENT_ITERATION_SEED = True \n",
        "PRECISION = \"autocast\" \n",
        "CACHE_PIPELINES = False\n",
        "RECACHE_PIPES = False \n",
        "SKIP_DIFFUSION_RUN = False \n",
        "ENABLE_NSFW_FILTER = False \n",
        "ENABLE_ATTENTION_SLICES = True \n",
        "LOW_VRAM_PATCH = True \n",
        "IMAGE_UPSCALER = \"CodeFormer + Enhanced ESRGAN\"\n",
        "UPSCALE_AMOUNT = 2\n",
        "ESRGAN_MODE = 'CPU'\n",
        "IMG2IMG_SAMPLER = 'LANCZOS'\n",
        "CODEFORMER_UPSCALE_AMOUNT = 1\n",
        "CODEFORMER_FIDELITY = 0.6\n",
        "HYBRID_UPSCALE = 'NONE'\n",
        "HYBRID_OVERLAY = 0.5\n",
        "HYBRID_SUPER_RESOLUTION = False\n",
        "KEEP_ONLY_FINAL_IMAGE = True\n",
        "SCALE_DOWN_ENHANCEMENTS_FOR_ESRGAN = True\n",
        "SHARPEN_AMOUNT = 1\n",
        "IMAGES_DISPLAY_ABOVE_LOG = False\n",
        "USE_BASIC_IMAGE_DISPLAY = False\n",
        "CLEAR_LOG_BETWEEN_ITERATIONS = True\n",
        "\n",
        "if LOAD_SETTINGS_FILE.lower() not in [None, 'none', '']:\n",
        "    try:\n",
        "        settings = json.load(open(LOAD_SETTINGS_FILE))\n",
        "    except OSError as e:\n",
        "        raise e\n",
        "    print(f'\\n:information: Loading \\'{LOAD_SETTINGS_FILE}\\' settings file...')\n",
        "    for ss in settings.keys():\n",
        "        for sk in settings[ss].keys():\n",
        "            if globals().__contains__(sk):\n",
        "                globals()[sk] = settings[ss][sk]\n",
        "    print(':information: Settings loaded.\\n')\n",
        "\n",
        "clean_env()\n",
        "\n",
        "last_diffusion_filedir = None\n",
        "\n",
        "download_model(MODEL_ID, REDOWNLOAD_MODEL)\n",
        "\n",
        "if CODEFORMER_UPSCALE_AMOUNT <= 0:\n",
        "    CODEFORMER_UPSCALE_AMOUNT = 1\n",
        "else:\n",
        "    CODEFORMER_UPSCALE_AMOUNT = closest_value([1,2,4,8],CODEFORMER_UPSCALE_AMOUNT)\n",
        "\n",
        "ESRGAN_MODE = ESRGAN_MODE.lower()\n",
        "\n",
        "if LOW_VRAM_PATCH and PRECISION is not 'autocast': \n",
        "    print(f\"PRECISION must be 'autocast' when running in low vram compatibility mode! Defaulting to autocast...\")\n",
        "    PRECISION = 'autocast'\n",
        "\n",
        "precision_scope = autocast if PRECISION is 'autocast' else nullcontext\n",
        "\n",
        "# Max Seed and Custom Seed Setup\n",
        "if MAX_SEED is 'system_max':\n",
        "    MAX_SEED = 9999999999999999\n",
        "else:\n",
        "    MAX_SEED = int(MAX_SEED)\n",
        "\n",
        "text_seed = None\n",
        "if type(SEED) is str:\n",
        "    text_seed = SEED\n",
        "    SEED = text2seed(SEED, 16)\n",
        "else:\n",
        "    SEED = int(SEED)\n",
        "\n",
        "ORIG_SEED = SEED\n",
        "\n",
        "os.chdir(STABLE_DIFFUSION_WORKDIR)      \n",
        "\n",
        "# JavaScript Compatible Boolean\n",
        "if IMAGES_DISPLAY_ABOVE_LOG:\n",
        "    IMAGES_DISPLAY_ABOVE_LOG = 1\n",
        "else:\n",
        "    IMAGES_DISPLAY_ABOVE_LOG = 0\n",
        "\n",
        "print(f\":open_file_folder: Images Output Directory: {OUTDIR}\\n\")\n",
        "\n",
        "if RECURSIVE_EVOLUTION is True:\n",
        "    print(\":gear: Recursive Evolution is Enabled\")\n",
        "\n",
        "# Nearest value to UPSCALE_AMOUNT\n",
        "nearest_value = closest_value([2,4,8],UPSCALE_AMOUNT)\n",
        "\n",
        "scraper.updateGlobals(globals())\n",
        "scraper.scrape('upscalers')\n",
        "scraper.scrape('image_processing')\n",
        "scraper.scrape('other_settings')\n",
        "\n",
        "# Diffuse Function\n",
        "def diffuse_run():\n",
        "\n",
        "    clean_env()\n",
        "\n",
        "    global RECACHE_PIPES, CACHE_PIPELINES, PROMPT, PROMPT_STYLE, SEED, UPSCALE_AMOUNT, GENERATE_MIDAS_DEPTH, FDOF_IMAGE, RECURSIVE_EVOLUTION, last_diffusion_filedir, init, original_init, original_mask, last_model_type, pipe_type, pipe_cache, opts\n",
        "    if not CACHE_PIPELINES: global pipe\n",
        "    else: pipe = None\n",
        "\n",
        "    if ORIG_SEED is 0 and SEED is 0:\n",
        "        SEED = random.randint(0,MAX_SEED)\n",
        "    else:\n",
        "        if INCREMENT_ITERATION_SEED and iteration > 0:\n",
        "            SEED += 1\n",
        "\n",
        "    if not os.path.exists(OUTDIR):\n",
        "        os.makedirs(OUTDIR)\n",
        "\n",
        "    scraper.updateGlobals(globals())\n",
        "    scraper.scrape('prompts')\n",
        "    scraper.scrape('inits')\n",
        "    scraper.scrape('diffusion_settings')\n",
        "\n",
        "    epoch_time = int(time.time())\n",
        "    if not SKIP_DIFFUSION_RUN:\n",
        "\n",
        "        gen_seed = torch.Generator(\"cuda\").manual_seed(SEED)\n",
        "        prompt_suffix = f' (Prompt Style: {PROMPT_STYLE})' if style.__contains__(PROMPT_STYLE) else ''\n",
        "        encoded_seed = f' (Encoded from: {text_seed})' if text_seed else ''\n",
        "        print(f\"\\n\\033[1mIteration {(iteration+1)}/{NUM_ITERS}\\033[0m\")\n",
        "        print(f':seedling: Seed: \\033[1m{SEED}{encoded_seed}\\033[0m, :framed_picture: Resolution: \\033[1m{WIDTH}x{HEIGHT}')\n",
        "        print(f\"\\033[0m:black_nib: Prompt{prompt_suffix}:\\033[1m\")\n",
        "        printPrompt(PROMPT)\n",
        "        print(\"\\033[0m\\n\")\n",
        "\n",
        "        # Parse Prompt\n",
        "        NEG_PROMPT = ''\n",
        "        if '--' in PROMPT:\n",
        "            pparts = [p.strip() for p in PROMPT.split('--')]; PROMPT = pparts[0]; NEG_PROMPT = pparts[1]\n",
        "\n",
        "        # Apply Style\n",
        "        if PROMPT_STYLE.lower() not in [None, 'none', ''] and style.__contains__(PROMPT_STYLE):\n",
        "            sparts = [s.strip() for s in style[PROMPT_STYLE].split('--')]; PROMPT += f', {sparts[0]}'; NEG_PROMPT += f', {sparts[1]}'\n",
        "\n",
        "        # Load Cached Pipelines\n",
        "        if CACHE_PIPELINES:\n",
        "            if MODEL_ID is not last_model_type:\n",
        "                RECACHE_PIPE = True\n",
        "            clean_env()\n",
        "            stt = int(time.time())\n",
        "            print(':gear: Loading Stable Diffusion Pipeline from cache...')\n",
        "            pipe = cache_pipes(pipe_type, MODEL_ID, model_cache, pipe_cache)\n",
        "            if pipe is None:\n",
        "                raise Exception(\":warning: Unable to load pipe from cache!\")\n",
        "            fnt = time_format(int(time.time()) - stt)\n",
        "            print(f':check_mark_button: Pipeline loaded in {fnt}')\n",
        "\n",
        "    if init is not None:\n",
        "        if USE_BASIC_IMAGE_DISPLAY:\n",
        "            print(\"Resized Init Image:\")\n",
        "            display(original_init)\n",
        "        else:\n",
        "            displayJsImage((i+1), (iteration+1), IMAGES_DISPLAY_ABOVE_LOG, f'Resized Init Image B: {(i+1)} I: {(iteration+1)}', original_init)\n",
        "        if SKIP_DIFFUSION_RUN:\n",
        "            image = original_init.copy()\n",
        "\n",
        "    if mask is not None:\n",
        "        if USE_BASIC_IMAGE_DISPLAY:\n",
        "            print(\"Resized Mask Image:\")\n",
        "            display(original_mask)\n",
        "        else:\n",
        "            displayJsImage((i+1), (iteration+1), IMAGES_DISPLAY_ABOVE_LOG, f'Resized Mask Image B: {(i+1)} I: {(iteration+1)}', original_mask)\n",
        "\n",
        "    # Setup Pipes\n",
        "    if not SKIP_DIFFUSION_RUN:\n",
        "\n",
        "        if SAMPLER is 'DEFAULT':\n",
        "            pipe.scheduler = PNDMScheduler (\n",
        "                trained_betas= None,\n",
        "                beta_end= 0.012,\n",
        "                beta_schedule= \"scaled_linear\",\n",
        "                beta_start= 0.00085,\n",
        "                num_train_timesteps= 1000,\n",
        "                skip_prk_steps= True\n",
        "            )\n",
        "        if SAMPLER == 'PNDM':\n",
        "            pipe.scheduler = PNDMScheduler(\n",
        "                trained_betas= None,\n",
        "                beta_start=0.00085, \n",
        "                beta_end=0.012, \n",
        "                beta_schedule=\"scaled_linear\", \n",
        "                num_train_timesteps=1000\n",
        "            )\n",
        "        elif SAMPLER == 'LMS':\n",
        "            pipe.scheduler = LMSDiscreteScheduler(\n",
        "                trained_betas= None,\n",
        "                beta_start=0.00085,\n",
        "                beta_end=0.012,\n",
        "                beta_schedule=\"scaled_linear\",\n",
        "                num_train_timesteps=1000\n",
        "            )\n",
        "        elif SAMPLER == 'DDIM':\n",
        "            pipe.scheduler = DDIMScheduler(\n",
        "                trained_betas= None,\n",
        "                beta_start=0.00085,\n",
        "                beta_end=0.012,\n",
        "                beta_schedule=\"scaled_linear\", \n",
        "                clip_sample=False,\n",
        "                set_alpha_to_one=False\n",
        "            )\n",
        "\n",
        "        if ENABLE_ATTENTION_SLICES:\n",
        "            print(':gear: Attention Slices Enabled')\n",
        "            pipe.enable_attention_slicing()\n",
        "        else:\n",
        "            pipe.disable_attention_slicing()\n",
        "        print(':check_mark_button: Pipeline setup complete.')\n",
        "\n",
        "        # Do diffusion\n",
        "        pipeout = None\n",
        "        last_model_type = MODEL_ID\n",
        "        try:\n",
        "            stt = int(time.time())\n",
        "            print(f\":alembic: Starting Diffusion run with {MODEL_ID}\")\n",
        "            if init is not None:\n",
        "                if mask is not None:\n",
        "                    with autocast(\"cuda\"):\n",
        "                        pipeout = pipe(prompt=PROMPT, negative_prompt=NEG_PROMPT, num_inference_steps=STEPS, init_image=init, mask_image=mask, strength=INIT_SCALE, guidance_scale=SCALE, generator=gen_seed)\n",
        "                        image = pipeout[\"sample\"][0]\n",
        "                else:\n",
        "                    with autocast(\"cuda\"):\n",
        "                        pipeout = pipe(prompt=PROMPT, negative_prompt=NEG_PROMPT, num_inference_steps=STEPS, init_image=init, strength=INIT_SCALE, guidance_scale=SCALE, generator=gen_seed)\n",
        "                        image = pipeout[\"sample\"][0]\n",
        "            else:\n",
        "                if SAMPLER == 'ddim':\n",
        "                    pipeout = pipe(prompt=PROMPT, negative_prompt=NEG_PROMPT, num_inference_steps=STEPS, width=int(WIDTH), height=int(HEIGHT), guidance_scale=SCALE, eta=DDIM_ETA, generator=gen_seed)\n",
        "                    image = pipeout[\"sample\"][0]\n",
        "                else:\n",
        "                    pipeout = pipe(prompt=PROMPT, negative_prompt=NEG_PROMPT, num_inference_steps=STEPS, width=int(WIDTH), height=int(HEIGHT), guidance_scale=SCALE, generator=gen_seed)\n",
        "                    image = pipeout[\"sample\"][0]\n",
        "        except BaseException as e:\n",
        "            raise e\n",
        "        finally:\n",
        "            if pipeout and pipeout['nsfw_content_detected'][0] and ENABLE_NSFW_FILTER:\n",
        "                print(\":passport_control: Censoring NSFW content...\")\n",
        "                image = image.filter(ImageFilter.GaussianBlur(radius = 18))\n",
        "            if CACHE_PIPELINES and not SKIP_DIFFUSION_RUN:\n",
        "                print(\":gear: Deleting pipeline...\")\n",
        "                del pipeout, pipe\n",
        "            fnt = time_format(int(time.time()) - stt)\n",
        "            print(f':check_mark_button: Diffusion completed in {fnt}')\n",
        "            clean_env()\n",
        "\n",
        "    filename = f'{str(epoch_time)}_scale_{SCALE}_steps_{STEPS}_seed_{SEED}.png'\n",
        "    filedir = f'{OUTDIR}/{filename}'\n",
        "    image.save(filedir)\n",
        "\n",
        "    # Do Sharpen\n",
        "    if SHARPEN_AMOUNT > 0:\n",
        "        stt = int(time.time())\n",
        "        print(f\"Sharpening diffusion result with {SHARPEN_AMOUNT} passes.\")\n",
        "        image = sharpenImage(image, SHARPEN_AMOUNT)\n",
        "        fnt = time_format(int(time.time()) - stt)\n",
        "        print(f'Sharpening completed in {fnt}')\n",
        "        clean_env()\n",
        "\n",
        "    main_img_title = 'SD Image'\n",
        "\n",
        "    # Display Diffusion Image\n",
        "    if USE_BASIC_IMAGE_DISPLAY:\n",
        "        print(\"Diffusion Image:\")\n",
        "        display(image)\n",
        "    else:\n",
        "        displayJsImage((i+1), (iteration+1), IMAGES_DISPLAY_ABOVE_LOG, f'{main_img_title} B: {(i+1)} I: {(iteration+1)}', image)\n",
        "\n",
        "    if IMAGE_UPSCALER == \"CodeFormer + Enhanced ESRGAN\":\n",
        "        if not opts['CODEFORMER_INSTALLED']:\n",
        "            install_codeformer()\n",
        "        if not opts['ESRGAN_INSTALLED']:\n",
        "            install_realesrgan()\n",
        "        stt = int(time.time())\n",
        "        fidelity = float(CODEFORMER_FIDELITY)\n",
        "        if fidelity is 0:\n",
        "            fidelity = '0.0'\n",
        "        clean_env()\n",
        "        # CodeFormer\n",
        "        print(\":sparkle: CodeFormer Face Restoration... \")\n",
        "        print(subprocess.run(f'cp {filedir} {STABLE_DIFFUSION_WORKDIR}/CodeFormer/temp/'.split(\" \"), stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "        os.chdir(f'{STABLE_DIFFUSION_WORKDIR}/CodeFormer')\n",
        "        print(subprocess.run(f'python inference_codeformer.py --w {fidelity} --test_path {STABLE_DIFFUSION_WORKDIR}/CodeFormer/temp --bg_upsampler realesrgan'.split(\" \"), stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "        os.remove(f'{STABLE_DIFFUSION_WORKDIR}/CodeFormer/temp/{filename}')\n",
        "        cftarget = f'{OUTDIR}/{filename.replace(\".png\",\"\")}_upscaled_{CODEFORMER_UPSCALE_AMOUNT}.png' if not KEEP_ONLY_FINAL_IMAGE else filedir\n",
        "        shutil.copyfile(f'{STABLE_DIFFUSION_WORKDIR}/CodeFormer/results/temp_{fidelity}/final_results/{filename}', cftarget)\n",
        "            \n",
        "        # Real-ESRGAN\n",
        "        os.chdir(f'{STABLE_DIFFUSION_WORKDIR}/Real-ESRGAN')\n",
        "        enhanced_image = Image.open(cftarget)\n",
        "        if SCALE_DOWN_ENHANCEMENTS_FOR_ESRGAN:\n",
        "            enhanced_image = enhanced_image.resize((WIDTH,HEIGHT))\n",
        "        if USE_BASIC_IMAGE_DISPLAY:\n",
        "            print('CodeFormer Image:')\n",
        "            display(enhanced_image)\n",
        "        else:\n",
        "            displayJsImage((i+1), (iteration+1), IMAGES_DISPLAY_ABOVE_LOG, f'CodeFormer B: {(i+1)} I: {(iteration+1)}', enhanced_image)\n",
        "        print(\":multiply: Real-ESRGAN Upscaling... \")\n",
        "        if UPSCALE_AMOUNT not in [2,4,8]:\n",
        "            UPSCALE_AMOUNT = nearest_value\n",
        "            print(f'For Real-ESRGAN upscaling only 2, 4, and 8 are supported. Choosing the nearest Value: {nearest_value}')\n",
        "        sr_image = upscale(enhanced_image, UPSCALE_AMOUNT, ESRGAN_MODE)\n",
        "        if HYBRID_UPSCALE.lower() not in [None, 'none', '']:\n",
        "            sr_iamge = overlayImage(sr_image, image, HYBRID_OVERLAY, HYBRID_UPSCALE, HYBRID_SUPER_RESOLUTION)\n",
        "        if USE_BASIC_IMAGE_DISPLAY:\n",
        "            print('Real-ESRGAN Image:')\n",
        "            display(sr_image)\n",
        "        else:\n",
        "            displayJsImage((i+1), (iteration+1), IMAGES_DISPLAY_ABOVE_LOG, f'Real-ESRGAN B: {(i+1)} I: {(iteration+1)}', sr_image)\n",
        "        if not KEEP_ONLY_FINAL_IMAGE:\n",
        "            sr_image.save(f'{OUTDIR}/{filename.replace(\".png\",\"\")}_upscaled_{UPSCALE_AMOUNT}.png')\n",
        "        else:\n",
        "            sr_image.save(filedir)\n",
        "        sr_image.close()\n",
        "        del sr_image\n",
        "        enhanced_image.close()\n",
        "        del enhanced_image\n",
        "        fnt = time_format(int(time.time()) - stt)\n",
        "        print(f'CodeFormer + Real-ESRGAN completed in {fnt}')\n",
        "        clean_env()\n",
        "\n",
        "    if SAVE_SETTING_FILE:\n",
        "        epoch_time = int(time.time())\n",
        "        with open(f'{OUTDIR}/{epoch_time}_settings.txt', 'w') as file:\n",
        "            file.write(json.dumps(scraper.params, indent=4))\n",
        "\n",
        "    image.close()\n",
        "    del image\n",
        "    if KEEP_ONLY_FINAL_IMAGE:\n",
        "        if os.path.exists(f'{OUTDIR}/cmp'):\n",
        "            shutil.rmtree(f'{OUTDIR}/cmp')\n",
        "        if os.path.exists(f'{OUTDIR}/cropped_faces'):\n",
        "            shutil.rmtree(f'{OUTDIR}/cropped_faces')\n",
        "        if os.path.exists(f'{OUTDIR}/restored_faces'):\n",
        "            shutil.rmtree(f'{OUTDIR}/restored_faces')\n",
        "        if os.path.exists(f'{OUTDIR}/restored_imgs'):\n",
        "            shutil.rmtree(f'{OUTDIR}/restored_imgs')\n",
        "\n",
        "    if CLEAR_LOG_BETWEEN_ITERATIONS and not USE_BASIC_IMAGE_DISPLAY:\n",
        "        clearOutputArea(i, iteration);\n",
        "\n",
        "# End Diffuse Function\n",
        "\n",
        "# Setup Prompts\n",
        "if PROMPT.lower() in [None, '', 'none'] and PROMPT_FILE in [None, '', 'none']:\n",
        "    raise AttributeError(\"PROMPT and PROMPT_FILE are empty! You need to provide a PROMPT or PROMPT_FILE!\")\n",
        "\n",
        "PROMPTS = []\n",
        "if PROMPT_FILE not in ['','none']:\n",
        "    try:\n",
        "        with open(PROMPT_FILE, \"r\") as f:\n",
        "            PROMPTS = f.read().splitlines()\n",
        "    except OSError as e:\n",
        "        raise e\n",
        "        \n",
        "# Insert prompt string first\n",
        "if PROMPT not in ['', 'none']:\n",
        "    PROMPTS.insert(0, PROMPT)\n",
        "\n",
        "#Get corrected sizes\n",
        "WX = (WIDTH//64)*64;\n",
        "HY = (HEIGHT//64)*64;\n",
        "if int(WX) != int(WIDTH) or int(HY) != int(HEIGHT):\n",
        "    print(f':warning: Changing output size to {WX}x{HY}. Dimensions must by multiples of 64.')\n",
        "    WIDTH = WX\n",
        "    HEIGHT = HY\n",
        "\n",
        "# Setup init_iamge\n",
        "inits = None\n",
        "masks = None\n",
        "init = None\n",
        "mask = None\n",
        "if INIT_IMAGE.lower() not in [None, '', 'none']:\n",
        "    print(\":hourglass_not_done: Searching for init images...\")\n",
        "    if INIT_IMAGE.lower().startswith('http://') or INIT_IMAGE.lower().startswith('https://'):\n",
        "        inits = INIT_IMAGE\n",
        "    else:\n",
        "        inits = getInitImages(INIT_IMAGE, INIT_FILTERS, True)\n",
        "    if inits is not None:\n",
        "        pipe_type = 'img2img'\n",
        "    else:\n",
        "        print(f\":WARNING: No valid image(s) found in {INIT_IMAGE}. Switching to default Text-to-Image run...\")\n",
        "        pipe_type = 'lowvram' if LOW_VRAM_PATCH else 'default'\n",
        "\n",
        "else:\n",
        "    pipe_type = 'lowvram' if LOW_VRAM_PATCH else 'default'\n",
        "    \n",
        "if INIT_MASK.lower() not in [None, '', 'none']:\n",
        "    print(\":hourglass_not_done: Searching for mask images...\")\n",
        "    if INIT_MASK.lower().startswith('http://') or INIT_MASK.lower().startswith('https://'):\n",
        "        masks = [INIT_MASK]\n",
        "    else:\n",
        "        masks = getInitImages(INIT_MASK, INIT_FILTERS, True)\n",
        "    if masks is not None:\n",
        "        pipe_type = 'inpaint'\n",
        "    else:\n",
        "        if inits is None:\n",
        "            print(f\":WARNING: No valid mask image(s) found in {INIT_MASK}. Switching to default Text-to-Image run...\")\n",
        "            pipe_type = 'lowvram' if LOW_VRAM_PATCH else 'default'\n",
        "        else:\n",
        "            print(f\":WARNING: No valid mask image(s) found in {INIT_MASK}. Switching to default Image-to-Image run...\")\n",
        "            pipe_type = 'img2img'\n",
        "\n",
        "# Initiate non-cached pipelines\n",
        "if not CACHE_PIPELINES and not SKIP_DIFFUSION_RUN:\n",
        "    print(\"Setting up diffusion model pipeline...\")\n",
        "    try:\n",
        "        if pipe and pipe is not None:\n",
        "            print(\":computer_disk: Pipeline already in memory. Starting diffusion environment...\\n\")\n",
        "    except NameError:\n",
        "        pipe = setup_pipes(pipe_type, MODEL_ID, model_cache)\n",
        "        pass\n",
        "    if ( last_diffusion_filedir is None \n",
        "            and inits is None \n",
        "            and type(pipe) is not StableDiffusionPipeline ):\n",
        "        print(\"Pipeline in memory is is a img2img-type pipeline, but no INIT_IMAGE or Evolution is defined.\")\n",
        "        pipe = setup_pipes('lowvram', MODEL_ID, model_cache) if LOW_VRAM_PATCH else setup_pipes('default', MODEL_ID, model_cache)\n",
        "        pipe_type = 'lowvram' if LOW_VRAM_PATCH else 'default'\n",
        "    if pipe_type is not last_pipe_type:\n",
        "        pipe = setup_pipes(pipe_type, MODEL_ID, model_cache)\n",
        "    if ENABLE_ATTENTION_SLICES:\n",
        "        print(':gear: Attention Slices Enabled.')\n",
        "        pipe.enable_attention_slicing()\n",
        "        #optimize_attention(pipe.unet)\n",
        "    else:\n",
        "        print(':gear: Attention Slices Disabled.')\n",
        "        pipe.disable_attention_slicing()\n",
        "    print(':check_mark_button: Pipeline setup complete.')\n",
        "\n",
        "last_pipe_type = pipe_type\n",
        "\n",
        "with torch.no_grad():\n",
        "    with precision_scope(\"cuda\"):\n",
        "\n",
        "        # Hack in Image List Support\n",
        "        DO = None\n",
        "        if type(inits) is list:\n",
        "            ITERATE_THIS = inits\n",
        "            DO = 'inits'\n",
        "        else:\n",
        "            ITERATE_THIS = PROMPTS\n",
        "            DO = 'prompts'\n",
        "\n",
        "        i = 0\n",
        "        for pi in ITERATE_THIS: # Replace PROMPTS with ITERATE_THIS switch\n",
        "\n",
        "            if DO is 'inits':\n",
        "                init = pi\n",
        "                if i > len(PROMPTS)-1:\n",
        "                    pi = PROMPTS[-1]\n",
        "                else:\n",
        "                    pi = PROMPTS[i]\n",
        "                if masks:\n",
        "                    if i > len(masks)-1:\n",
        "                        mask = masks[-1]\n",
        "                    else:\n",
        "                        mask = masks[i]\n",
        "                else:\n",
        "                    mask = None\n",
        "            elif DO is 'prompts':\n",
        "                if inits is not None:\n",
        "                    init = inits\n",
        "                if masks:\n",
        "                    if type(masks) is list:\n",
        "                        if i > len(masks)-1:\n",
        "                            mask = masks[-1]\n",
        "                        else:\n",
        "                            mask = masks[i]\n",
        "                    else:\n",
        "                        mask = masks\n",
        "                else:\n",
        "                    mask = None\n",
        "            if init:    \n",
        "                from PIL import ImageOps\n",
        "                init = Image.open(fetch(init)).convert(\"RGB\")\n",
        "                #init = ImageOps.exif_transpose(init)\n",
        "                init = init.resize((WIDTH,HEIGHT))\n",
        "                original_init = init.copy()\n",
        "                #init = preprocess(init)\n",
        "            if mask:    \n",
        "                from PIL import ImageOps\n",
        "                mask = Image.open(fetch(mask)).convert(\"RGB\")\n",
        "                #mask = ImageOps.exif_transpose(mask)\n",
        "                mask = mask.resize((WIDTH,HEIGHT))\n",
        "                original_mask = mask.copy()\n",
        "                #mask = preprocess(mask)\n",
        "\n",
        "            # Define Run Prompt\n",
        "            if NEW_NSP_ON_ITERATION is not True:\n",
        "                PROMPT = nsp_parse(pi)\n",
        "\n",
        "            for iteration in range(NUM_ITERS):\n",
        "\n",
        "                # Define Iteration Prompt\n",
        "                if NEW_NSP_ON_ITERATION:\n",
        "                    PROMPT = nsp_parse(pi)\n",
        "\n",
        "                try:\n",
        "\n",
        "                    diffuse_run()\n",
        "\n",
        "                except RuntimeError as e:\n",
        "                    if 'out of memory' in str(e):\n",
        "                        print(f\"\\u001b[31m\\u001b[1m\\u001b[4mCRITICAL ERROR\\u001b[0m: {gpu_name} ran out of memory! If this error persists, the GPU may have crashed, and requires a disconnect/re-run.\")\n",
        "                        pass\n",
        "                    else:\n",
        "                        raise e\n",
        "                except KeyboardInterrupt as e:\n",
        "                    raise SystemExit('\\33[33mExecution interrupted by user.\\33[0m')\n",
        "                except Exception as e:\n",
        "                    raise e\n",
        "                finally:\n",
        "                    clean_env()\n",
        "                    \n",
        "            i+=1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <a name=\"cleanenv\"><font color=\"orange\">**Clean Environment Up**</font></a>\n",
        "#@markdown <font size=\"3\">**Soft Reset** the environment by loaded models and variables.\n",
        "delete = ['pipe','pipeout','midas','transform','prediction','input_batch','depth','depth_image','image','sr_image','enhanced_img','img','init','original_init','orig_init','model']\n",
        "for d in delete:\n",
        "    try:\n",
        "        if globals().__contains__(d):\n",
        "            del globals()[d]\n",
        "    except NameError:\n",
        "        pass\n",
        "\n",
        "for clnc in range(1,6):\n",
        "    print(f\"Sweeping cycle {clnc}\")\n",
        "    clean_env(True)\n",
        "    time.sleep(5)\n",
        "    if clnc != 5:\n",
        "        clear()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "RjZhn2vwEydT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}